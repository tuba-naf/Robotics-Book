---
id: weekly-breakdown
title: Weekly Breakdown
---

# Weekly Breakdown

This section outlines the course content on a weekly basis.
# Week-by-Week Roadmap

This course is structured to gradually take you from foundational concepts to building a fully functional humanoid robot. Each week introduces new skills while building on what you’ve learned before, ensuring a smooth progression from theory to hands-on implementation.

---

| Week | Focus | What You Learn / Do |
|------|-------|---------------------|
| 1–2 | Foundations of Physical AI | Understand the principles of **Physical AI** and embodied intelligence. Explore sensor types like LIDAR, cameras, and IMUs. Learn why humanoid robots are designed like humans. |
| 3–5 | ROS 2 Fundamentals | Dive into **nodes, topics, and actions**. Build a simple “nervous system” for your robot. Understand packages, launch files, and parameter management. Start controlling a basic robot skeleton. |
| 6–7 | Simulation with Gazebo | Set up your **digital twin** environment. Create URDF/SDF robot models. Add sensors and simulate physics like gravity, friction, and collisions. Learn Unity basics for visualization. |
| 8–10 | AI Brain with NVIDIA Isaac | Develop perception, mapping, and navigation pipelines. Use **Isaac Sim** for realistic simulation and synthetic data. Implement VSLAM and reinforcement learning for robot motion. |
| 11–12 | Humanoid Motion & Manipulation | Model humanoid kinematics, implement walking and balance control. Enable your robot to manipulate objects using hands. Fine-tune natural human-robot interaction. |
| 13 | Conversational Robotics & Capstone | Integrate **GPT-based language understanding**. Convert voice commands into sequences of robot actions. Prepare and finalize your **capstone project**: a fully autonomous humanoid robot. |

---

## Why the Weekly Structure Works

Each module is like a **level in a game**. You start with basics, unlock skills, and gradually tackle more complex challenges:

- Foundations let you understand what makes robots “alive.”  
- ROS 2 modules teach the robot to sense and act — its nervous system.  
- Simulations give a **risk-free playground** to test behaviors.  
- NVIDIA Isaac adds perception and decision-making — the robot starts thinking.  
- Humanoid motion ensures the robot **walks, balances, and interacts naturally**.  
- Finally, conversational robotics bridges human language and robot action — your robot responds like a real assistant.  

By the end, you’ll have **step-by-step experience** turning concepts into a robot that can move, see, think, and act.

---

## Key Resources

- [ROS 2 Tutorials](https://docs.ros.org/en/rolling/Tutorials.html) — Node and topic examples  
- [Gazebo Tutorials](http://gazebosim.org/tutorials) — Physics and sensor simulation  
- [Unity Robotics Hub](https://unity.com/solutions/robotics) — Integrate simulations with visuals  
- [NVIDIA Isaac Sim Docs](https://developer.nvidia.com/isaac-sim) — AI perception and navigation pipelines  
- [OpenAI GPT API](https://platform.openai.com/docs/) — Voice-to-action integration

